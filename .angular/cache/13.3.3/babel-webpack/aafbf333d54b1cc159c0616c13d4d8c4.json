{"ast":null,"code":"import _asyncToGenerator from \"C:\\\\GitHub\\\\Private\\\\Angular_WebApp\\\\node_modules\\\\@babel\\\\runtime\\\\helpers\\\\esm\\\\asyncToGenerator.js\";\nimport { generateUuid, getDefaultProxySettings, isNode, isTokenCredential, URLBuilder } from \"@azure/core-http\";\nimport { SpanStatusCode } from \"@azure/core-tracing\";\nimport { BlobDownloadResponse } from \"./BlobDownloadResponse\";\nimport { BlobQueryResponse } from \"./BlobQueryResponse\";\nimport { AnonymousCredential } from \"./credentials/AnonymousCredential\";\nimport { StorageSharedKeyCredential } from \"./credentials/StorageSharedKeyCredential\";\nimport { AppendBlob, Blob as StorageBlob, BlockBlob, PageBlob } from \"./generated/src/operations\";\nimport { ensureCpkIfSpecified, toAccessTier } from \"./models\";\nimport { rangeResponseFromModel } from \"./PageBlobRangeResponse\";\nimport { newPipeline, isPipelineLike } from \"./Pipeline\";\nimport { BlobBeginCopyFromUrlPoller } from \"./pollers/BlobStartCopyFromUrlPoller\";\nimport { rangeToString } from \"./Range\";\nimport { StorageClient } from \"./StorageClient\";\nimport { Batch } from \"./utils/Batch\";\nimport { BufferScheduler } from \"../../storage-common/src\";\nimport { BlobUsesCustomerSpecifiedEncryptionMsg, BLOCK_BLOB_MAX_BLOCKS, BLOCK_BLOB_MAX_STAGE_BLOCK_BYTES, BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES, DEFAULT_BLOB_DOWNLOAD_BLOCK_BYTES, DEFAULT_BLOCK_BUFFER_SIZE_BYTES, DEFAULT_MAX_DOWNLOAD_RETRY_REQUESTS, ETagAny, URLConstants } from \"./utils/constants\";\nimport { createSpan, convertTracingToRequestOptionsBase } from \"./utils/tracing\";\nimport { appendToURLPath, appendToURLQuery, extractConnectionStringParts, generateBlockID, getURLParameter, httpAuthorizationToString, isIpEndpointStyle, parseObjectReplicationRecord, setURLParameter, toBlobTags, toBlobTagsString, toQuerySerialization, toTags } from \"./utils/utils.common\";\nimport { fsCreateReadStream, fsStat, readStreamToLocalFile, streamToBuffer } from \"./utils/utils.node\";\nimport { generateBlobSASQueryParameters } from \"./sas/BlobSASSignatureValues\";\nimport { BlobLeaseClient } from \"./BlobLeaseClient\";\n/**\n * A BlobClient represents a URL to an Azure Storage blob; the blob may be a block blob,\n * append blob, or page blob.\n */\n\nexport class BlobClient extends StorageClient {\n  constructor(urlOrConnectionString, credentialOrPipelineOrContainerName, blobNameOrOptions, // Legacy, no fix for eslint error without breaking. Disable it for this interface.\n\n  /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/\n  options) {\n    options = options || {};\n    let pipeline;\n    let url;\n\n    if (isPipelineLike(credentialOrPipelineOrContainerName)) {\n      // (url: string, pipeline: Pipeline)\n      url = urlOrConnectionString;\n      pipeline = credentialOrPipelineOrContainerName;\n    } else if (isNode && credentialOrPipelineOrContainerName instanceof StorageSharedKeyCredential || credentialOrPipelineOrContainerName instanceof AnonymousCredential || isTokenCredential(credentialOrPipelineOrContainerName)) {\n      // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)\n      url = urlOrConnectionString;\n      options = blobNameOrOptions;\n      pipeline = newPipeline(credentialOrPipelineOrContainerName, options);\n    } else if (!credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName !== \"string\") {\n      // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)\n      // The second parameter is undefined. Use anonymous credential.\n      url = urlOrConnectionString;\n      pipeline = newPipeline(new AnonymousCredential(), options);\n    } else if (credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName === \"string\" && blobNameOrOptions && typeof blobNameOrOptions === \"string\") {\n      // (connectionString: string, containerName: string, blobName: string, options?: StoragePipelineOptions)\n      const containerName = credentialOrPipelineOrContainerName;\n      const blobName = blobNameOrOptions;\n      const extractedCreds = extractConnectionStringParts(urlOrConnectionString);\n\n      if (extractedCreds.kind === \"AccountConnString\") {\n        if (isNode) {\n          const sharedKeyCredential = new StorageSharedKeyCredential(extractedCreds.accountName, extractedCreds.accountKey);\n          url = appendToURLPath(appendToURLPath(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName));\n\n          if (!options.proxyOptions) {\n            options.proxyOptions = getDefaultProxySettings(extractedCreds.proxyUri);\n          }\n\n          pipeline = newPipeline(sharedKeyCredential, options);\n        } else {\n          throw new Error(\"Account connection string is only supported in Node.js environment\");\n        }\n      } else if (extractedCreds.kind === \"SASConnString\") {\n        url = appendToURLPath(appendToURLPath(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName)) + \"?\" + extractedCreds.accountSas;\n        pipeline = newPipeline(new AnonymousCredential(), options);\n      } else {\n        throw new Error(\"Connection string must be either an Account connection string or a SAS connection string\");\n      }\n    } else {\n      throw new Error(\"Expecting non-empty strings for containerName and blobName parameters\");\n    }\n\n    super(url, pipeline);\n    ({\n      blobName: this._name,\n      containerName: this._containerName\n    } = this.getBlobAndContainerNamesFromUrl());\n    this.blobContext = new StorageBlob(this.storageClientContext);\n    this._snapshot = getURLParameter(this.url, URLConstants.Parameters.SNAPSHOT);\n    this._versionId = getURLParameter(this.url, URLConstants.Parameters.VERSIONID);\n  }\n  /**\n   * The name of the blob.\n   */\n\n\n  get name() {\n    return this._name;\n  }\n  /**\n   * The name of the storage container the blob is associated with.\n   */\n\n\n  get containerName() {\n    return this._containerName;\n  }\n  /**\n   * Creates a new BlobClient object identical to the source but with the specified snapshot timestamp.\n   * Provide \"\" will remove the snapshot and return a Client to the base blob.\n   *\n   * @param snapshot - The snapshot timestamp.\n   * @returns A new BlobClient object identical to the source but with the specified snapshot timestamp\n   */\n\n\n  withSnapshot(snapshot) {\n    return new BlobClient(setURLParameter(this.url, URLConstants.Parameters.SNAPSHOT, snapshot.length === 0 ? undefined : snapshot), this.pipeline);\n  }\n  /**\n   * Creates a new BlobClient object pointing to a version of this blob.\n   * Provide \"\" will remove the versionId and return a Client to the base blob.\n   *\n   * @param versionId - The versionId.\n   * @returns A new BlobClient object pointing to the version of this blob.\n   */\n\n\n  withVersion(versionId) {\n    return new BlobClient(setURLParameter(this.url, URLConstants.Parameters.VERSIONID, versionId.length === 0 ? undefined : versionId), this.pipeline);\n  }\n  /**\n   * Creates a AppendBlobClient object.\n   *\n   */\n\n\n  getAppendBlobClient() {\n    return new AppendBlobClient(this.url, this.pipeline);\n  }\n  /**\n   * Creates a BlockBlobClient object.\n   *\n   */\n\n\n  getBlockBlobClient() {\n    return new BlockBlobClient(this.url, this.pipeline);\n  }\n  /**\n   * Creates a PageBlobClient object.\n   *\n   */\n\n\n  getPageBlobClient() {\n    return new PageBlobClient(this.url, this.pipeline);\n  }\n  /**\n   * Reads or downloads a blob from the system, including its metadata and properties.\n   * You can also call Get Blob to read a snapshot.\n   *\n   * * In Node.js, data returns in a Readable stream readableStreamBody\n   * * In browsers, data returns in a promise blobBody\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob\n   *\n   * @param offset - From which position of the blob to download, greater than or equal to 0\n   * @param count - How much data to be downloaded, greater than 0. Will download to the end when undefined\n   * @param options - Optional options to Blob Download operation.\n   *\n   *\n   * Example usage (Node.js):\n   *\n   * ```js\n   * // Download and convert a blob to a string\n   * const downloadBlockBlobResponse = await blobClient.download();\n   * const downloaded = await streamToBuffer(downloadBlockBlobResponse.readableStreamBody);\n   * console.log(\"Downloaded blob content:\", downloaded.toString());\n   *\n   * async function streamToBuffer(readableStream) {\n   * return new Promise((resolve, reject) => {\n   * const chunks = [];\n   * readableStream.on(\"data\", (data) => {\n   * chunks.push(data instanceof Buffer ? data : Buffer.from(data));\n   * });\n   * readableStream.on(\"end\", () => {\n   * resolve(Buffer.concat(chunks));\n   * });\n   * readableStream.on(\"error\", reject);\n   * });\n   * }\n   * ```\n   *\n   * Example usage (browser):\n   *\n   * ```js\n   * // Download and convert a blob to a string\n   * const downloadBlockBlobResponse = await blobClient.download();\n   * const downloaded = await blobToString(await downloadBlockBlobResponse.blobBody);\n   * console.log(\n   *   \"Downloaded blob content\",\n   *   downloaded\n   * );\n   *\n   * async function blobToString(blob: Blob): Promise<string> {\n   *   const fileReader = new FileReader();\n   *   return new Promise<string>((resolve, reject) => {\n   *     fileReader.onloadend = (ev: any) => {\n   *       resolve(ev.target!.result);\n   *     };\n   *     fileReader.onerror = reject;\n   *     fileReader.readAsText(blob);\n   *   });\n   * }\n   * ```\n   */\n\n\n  download(offset = 0, count, options = {}) {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      options.conditions = options.conditions || {};\n      options.conditions = options.conditions || {};\n      ensureCpkIfSpecified(options.customerProvidedKey, _this.isHttps);\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-download\", options);\n\n      try {\n        const res = yield _this.blobContext.download(Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          requestOptions: {\n            onDownloadProgress: isNode ? undefined : options.onProgress // for Node.js, progress is reported by RetriableReadableStream\n\n          },\n          range: offset === 0 && !count ? undefined : rangeToString({\n            offset,\n            count\n          }),\n          rangeGetContentMD5: options.rangeGetContentMD5,\n          rangeGetContentCRC64: options.rangeGetContentCrc64,\n          snapshot: options.snapshot,\n          cpkInfo: options.customerProvidedKey\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n        const wrappedRes = Object.assign(Object.assign({}, res), {\n          _response: res._response,\n          objectReplicationDestinationPolicyId: res.objectReplicationPolicyId,\n          objectReplicationSourceProperties: parseObjectReplicationRecord(res.objectReplicationRules)\n        }); // Return browser response immediately\n\n        if (!isNode) {\n          return wrappedRes;\n        } // We support retrying when download stream unexpected ends in Node.js runtime\n        // Following code shouldn't be bundled into browser build, however some\n        // bundlers may try to bundle following code and \"FileReadResponse.ts\".\n        // In this case, \"FileDownloadResponse.browser.ts\" will be used as a shim of \"FileDownloadResponse.ts\"\n        // The config is in package.json \"browser\" field\n\n\n        if (options.maxRetryRequests === undefined || options.maxRetryRequests < 0) {\n          // TODO: Default value or make it a required parameter?\n          options.maxRetryRequests = DEFAULT_MAX_DOWNLOAD_RETRY_REQUESTS;\n        }\n\n        if (res.contentLength === undefined) {\n          throw new RangeError(`File download response doesn't contain valid content length header`);\n        }\n\n        if (!res.etag) {\n          throw new RangeError(`File download response doesn't contain valid etag header`);\n        }\n\n        return new BlobDownloadResponse(wrappedRes, /*#__PURE__*/function () {\n          var _ref = _asyncToGenerator(function* (start) {\n            var _a;\n\n            const updatedDownloadOptions = {\n              leaseAccessConditions: options.conditions,\n              modifiedAccessConditions: {\n                ifMatch: options.conditions.ifMatch || res.etag,\n                ifModifiedSince: options.conditions.ifModifiedSince,\n                ifNoneMatch: options.conditions.ifNoneMatch,\n                ifUnmodifiedSince: options.conditions.ifUnmodifiedSince,\n                ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n              },\n              range: rangeToString({\n                count: offset + res.contentLength - start,\n                offset: start\n              }),\n              rangeGetContentMD5: options.rangeGetContentMD5,\n              rangeGetContentCRC64: options.rangeGetContentCrc64,\n              snapshot: options.snapshot,\n              cpkInfo: options.customerProvidedKey\n            }; // Debug purpose only\n            // console.log(\n            //   `Read from internal stream, range: ${\n            //     updatedOptions.range\n            //   }, options: ${JSON.stringify(updatedOptions)}`\n            // );\n\n            return (yield _this.blobContext.download(Object.assign({\n              abortSignal: options.abortSignal\n            }, updatedDownloadOptions))).readableStreamBody;\n          });\n\n          return function (_x) {\n            return _ref.apply(this, arguments);\n          };\n        }(), offset, res.contentLength, {\n          maxRetryRequests: options.maxRetryRequests,\n          onProgress: options.onProgress\n        });\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Returns true if the Azure blob resource represented by this client exists; false otherwise.\n   *\n   * NOTE: use this function with care since an existing blob might be deleted by other clients or\n   * applications. Vice versa new blobs might be added by other clients or applications after this\n   * function completes.\n   *\n   * @param options - options to Exists operation.\n   */\n\n\n  exists(options = {}) {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-exists\", options);\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this2.isHttps);\n        yield _this2.getProperties({\n          abortSignal: options.abortSignal,\n          customerProvidedKey: options.customerProvidedKey,\n          conditions: options.conditions,\n          tracingOptions: updatedOptions.tracingOptions\n        });\n        return true;\n      } catch (e) {\n        if (e.statusCode === 404) {\n          // Expected exception when checking blob existence\n          return false;\n        } else if (e.statusCode === 409 && e.details.errorCode === BlobUsesCustomerSpecifiedEncryptionMsg) {\n          // Expected exception when checking blob existence\n          return true;\n        }\n\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Returns all user-defined metadata, standard HTTP properties, and system properties\n   * for the blob. It does not return the content of the blob.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-properties\n   *\n   * WARNING: The `metadata` object returned in the response will have its keys in lowercase, even if\n   * they originally contained uppercase characters. This differs from the metadata keys returned by\n   * the methods of {@link ContainerClient} that list blobs using the `includeMetadata` option, which\n   * will retain their original casing.\n   *\n   * @param options - Optional options to Get Properties operation.\n   */\n\n\n  getProperties(options = {}) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-getProperties\", options);\n\n      try {\n        options.conditions = options.conditions || {};\n        ensureCpkIfSpecified(options.customerProvidedKey, _this3.isHttps);\n        const res = yield _this3.blobContext.getProperties(Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          cpkInfo: options.customerProvidedKey\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n        return Object.assign(Object.assign({}, res), {\n          _response: res._response,\n          objectReplicationDestinationPolicyId: res.objectReplicationPolicyId,\n          objectReplicationSourceProperties: parseObjectReplicationRecord(res.objectReplicationRules)\n        });\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Marks the specified blob or snapshot for deletion. The blob is later deleted\n   * during garbage collection. Note that in order to delete a blob, you must delete\n   * all of its snapshots. You can delete both at the same time with the Delete\n   * Blob operation.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-blob\n   *\n   * @param options - Optional options to Blob Delete operation.\n   */\n\n\n  delete(options = {}) {\n    var _this4 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-delete\", options);\n      options.conditions = options.conditions || {};\n\n      try {\n        return yield _this4.blobContext.delete(Object.assign({\n          abortSignal: options.abortSignal,\n          deleteSnapshots: options.deleteSnapshots,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Marks the specified blob or snapshot for deletion if it exists. The blob is later deleted\n   * during garbage collection. Note that in order to delete a blob, you must delete\n   * all of its snapshots. You can delete both at the same time with the Delete\n   * Blob operation.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-blob\n   *\n   * @param options - Optional options to Blob Delete operation.\n   */\n\n\n  deleteIfExists(options = {}) {\n    var _this5 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-deleteIfExists\", options);\n\n      try {\n        const res = yield _this5.delete(updatedOptions);\n        return Object.assign(Object.assign({\n          succeeded: true\n        }, res), {\n          _response: res._response\n        });\n      } catch (e) {\n        if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === \"BlobNotFound\") {\n          span.setStatus({\n            code: SpanStatusCode.ERROR,\n            message: \"Expected exception when deleting a blob or snapshot only if it exists.\"\n          });\n          return Object.assign(Object.assign({\n            succeeded: false\n          }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), {\n            _response: e.response\n          });\n        }\n\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Restores the contents and metadata of soft deleted blob and any associated\n   * soft deleted snapshots. Undelete Blob is supported only on version 2017-07-29\n   * or later.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/undelete-blob\n   *\n   * @param options - Optional options to Blob Undelete operation.\n   */\n\n\n  undelete(options = {}) {\n    var _this6 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-undelete\", options);\n\n      try {\n        return yield _this6.blobContext.undelete(Object.assign({\n          abortSignal: options.abortSignal\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Sets system properties on the blob.\n   *\n   * If no value provided, or no value provided for the specified blob HTTP headers,\n   * these blob HTTP headers without a value will be cleared.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-properties\n   *\n   * @param blobHTTPHeaders - If no value provided, or no value provided for\n   *                                                   the specified blob HTTP headers, these blob HTTP\n   *                                                   headers without a value will be cleared.\n   *                                                   A common header to set is `blobContentType`\n   *                                                   enabling the browser to provide functionality\n   *                                                   based on file type.\n   * @param options - Optional options to Blob Set HTTP Headers operation.\n   */\n\n\n  setHTTPHeaders(blobHTTPHeaders, options = {}) {\n    var _this7 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-setHTTPHeaders\", options);\n      options.conditions = options.conditions || {};\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this7.isHttps);\n        return yield _this7.blobContext.setHttpHeaders(Object.assign({\n          abortSignal: options.abortSignal,\n          blobHttpHeaders: blobHTTPHeaders,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Sets user-defined metadata for the specified blob as one or more name-value pairs.\n   *\n   * If no option provided, or no metadata defined in the parameter, the blob\n   * metadata will be removed.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-metadata\n   *\n   * @param metadata - Replace existing metadata with this value.\n   *                               If no value provided the existing metadata will be removed.\n   * @param options - Optional options to Set Metadata operation.\n   */\n\n\n  setMetadata(metadata, options = {}) {\n    var _this8 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-setMetadata\", options);\n      options.conditions = options.conditions || {};\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this8.isHttps);\n        return yield _this8.blobContext.setMetadata(Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          metadata,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Sets tags on the underlying blob.\n   * A blob can have up to 10 tags. Tag keys must be between 1 and 128 characters.  Tag values must be between 0 and 256 characters.\n   * Valid tag key and value characters include lower and upper case letters, digits (0-9),\n   * space (' '), plus ('+'), minus ('-'), period ('.'), foward slash ('/'), colon (':'), equals ('='), and underscore ('_').\n   *\n   * @param tags -\n   * @param options -\n   */\n\n\n  setTags(tags, options = {}) {\n    var _this9 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-setTags\", options);\n\n      try {\n        return yield _this9.blobContext.setTags(Object.assign(Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions)), {\n          tags: toBlobTags(tags)\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Gets the tags associated with the underlying blob.\n   *\n   * @param options -\n   */\n\n\n  getTags(options = {}) {\n    var _this10 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-getTags\", options);\n\n      try {\n        const response = yield _this10.blobContext.getTags(Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n        const wrappedResponse = Object.assign(Object.assign({}, response), {\n          _response: response._response,\n          tags: toTags({\n            blobTagSet: response.blobTagSet\n          }) || {}\n        });\n        return wrappedResponse;\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Get a {@link BlobLeaseClient} that manages leases on the blob.\n   *\n   * @param proposeLeaseId - Initial proposed lease Id.\n   * @returns A new BlobLeaseClient object for managing leases on the blob.\n   */\n\n\n  getBlobLeaseClient(proposeLeaseId) {\n    return new BlobLeaseClient(this, proposeLeaseId);\n  }\n  /**\n   * Creates a read-only snapshot of a blob.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/snapshot-blob\n   *\n   * @param options - Optional options to the Blob Create Snapshot operation.\n   */\n\n\n  createSnapshot(options = {}) {\n    var _this11 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-createSnapshot\", options);\n      options.conditions = options.conditions || {};\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this11.isHttps);\n        return yield _this11.blobContext.createSnapshot(Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          metadata: options.metadata,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Asynchronously copies a blob to a destination within the storage account.\n   * This method returns a long running operation poller that allows you to wait\n   * indefinitely until the copy is completed.\n   * You can also cancel a copy before it is completed by calling `cancelOperation` on the poller.\n   * Note that the onProgress callback will not be invoked if the operation completes in the first\n   * request, and attempting to cancel a completed copy will result in an error being thrown.\n   *\n   * In version 2012-02-12 and later, the source for a Copy Blob operation can be\n   * a committed blob in any Azure storage account.\n   * Beginning with version 2015-02-21, the source for a Copy Blob operation can be\n   * an Azure file in any Azure storage account.\n   * Only storage accounts created on or after June 7th, 2012 allow the Copy Blob\n   * operation to copy from another storage account.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/copy-blob\n   *\n   * Example using automatic polling:\n   *\n   * ```js\n   * const copyPoller = await blobClient.beginCopyFromURL('url');\n   * const result = await copyPoller.pollUntilDone();\n   * ```\n   *\n   * Example using manual polling:\n   *\n   * ```js\n   * const copyPoller = await blobClient.beginCopyFromURL('url');\n   * while (!poller.isDone()) {\n   *    await poller.poll();\n   * }\n   * const result = copyPoller.getResult();\n   * ```\n   *\n   * Example using progress updates:\n   *\n   * ```js\n   * const copyPoller = await blobClient.beginCopyFromURL('url', {\n   *   onProgress(state) {\n   *     console.log(`Progress: ${state.copyProgress}`);\n   *   }\n   * });\n   * const result = await copyPoller.pollUntilDone();\n   * ```\n   *\n   * Example using a changing polling interval (default 15 seconds):\n   *\n   * ```js\n   * const copyPoller = await blobClient.beginCopyFromURL('url', {\n   *   intervalInMs: 1000 // poll blob every 1 second for copy progress\n   * });\n   * const result = await copyPoller.pollUntilDone();\n   * ```\n   *\n   * Example using copy cancellation:\n   *\n   * ```js\n   * const copyPoller = await blobClient.beginCopyFromURL('url');\n   * // cancel operation after starting it.\n   * try {\n   *   await copyPoller.cancelOperation();\n   *   // calls to get the result now throw PollerCancelledError\n   *   await copyPoller.getResult();\n   * } catch (err) {\n   *   if (err.name === 'PollerCancelledError') {\n   *     console.log('The copy was cancelled.');\n   *   }\n   * }\n   * ```\n   *\n   * @param copySource - url to the source Azure Blob/File.\n   * @param options - Optional options to the Blob Start Copy From URL operation.\n   */\n\n\n  beginCopyFromURL(copySource, options = {}) {\n    var _this12 = this;\n\n    return _asyncToGenerator(function* () {\n      const client = {\n        abortCopyFromURL: (...args) => _this12.abortCopyFromURL(...args),\n        getProperties: (...args) => _this12.getProperties(...args),\n        startCopyFromURL: (...args) => _this12.startCopyFromURL(...args)\n      };\n      const poller = new BlobBeginCopyFromUrlPoller({\n        blobClient: client,\n        copySource,\n        intervalInMs: options.intervalInMs,\n        onProgress: options.onProgress,\n        resumeFrom: options.resumeFrom,\n        startCopyFromURLOptions: options\n      }); // Trigger the startCopyFromURL call by calling poll.\n      // Any errors from this method should be surfaced to the user.\n\n      yield poller.poll();\n      return poller;\n    })();\n  }\n  /**\n   * Aborts a pending asynchronous Copy Blob operation, and leaves a destination blob with zero\n   * length and full metadata. Version 2012-02-12 and newer.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/abort-copy-blob\n   *\n   * @param copyId - Id of the Copy From URL operation.\n   * @param options - Optional options to the Blob Abort Copy From URL operation.\n   */\n\n\n  abortCopyFromURL(copyId, options = {}) {\n    var _this13 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-abortCopyFromURL\", options);\n\n      try {\n        return yield _this13.blobContext.abortCopyFromURL(copyId, Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * The synchronous Copy From URL operation copies a blob or an internet resource to a new blob. It will not\n   * return a response until the copy is complete.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/copy-blob-from-url\n   *\n   * @param copySource - The source URL to copy from, Shared Access Signature(SAS) maybe needed for authentication\n   * @param options -\n   */\n\n\n  syncCopyFromURL(copySource, options = {}) {\n    var _this14 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b, _c;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-syncCopyFromURL\", options);\n      options.conditions = options.conditions || {};\n      options.sourceConditions = options.sourceConditions || {};\n\n      try {\n        return yield _this14.blobContext.copyFromURL(copySource, Object.assign({\n          abortSignal: options.abortSignal,\n          metadata: options.metadata,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          sourceModifiedAccessConditions: {\n            sourceIfMatch: options.sourceConditions.ifMatch,\n            sourceIfModifiedSince: options.sourceConditions.ifModifiedSince,\n            sourceIfNoneMatch: options.sourceConditions.ifNoneMatch,\n            sourceIfUnmodifiedSince: options.sourceConditions.ifUnmodifiedSince\n          },\n          sourceContentMD5: options.sourceContentMD5,\n          copySourceAuthorization: httpAuthorizationToString(options.sourceAuthorization),\n          blobTagsString: toBlobTagsString(options.tags),\n          immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,\n          immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,\n          legalHold: options.legalHold,\n          encryptionScope: options.encryptionScope\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Sets the tier on a blob. The operation is allowed on a page blob in a premium\n   * storage account and on a block blob in a blob storage account (locally redundant\n   * storage only). A premium page blob's tier determines the allowed size, IOPS,\n   * and bandwidth of the blob. A block blob's tier determines Hot/Cool/Archive\n   * storage type. This operation does not update the blob's ETag.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-tier\n   *\n   * @param tier - The tier to be set on the blob. Valid values are Hot, Cool, or Archive.\n   * @param options - Optional options to the Blob Set Tier operation.\n   */\n\n\n  setAccessTier(tier, options = {}) {\n    var _this15 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-setAccessTier\", options);\n\n      try {\n        return yield _this15.blobContext.setTier(toAccessTier(tier), Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          rehydratePriority: options.rehydratePriority\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n  downloadToBuffer(param1, param2, param3, param4 = {}) {\n    var _this16 = this;\n\n    return _asyncToGenerator(function* () {\n      let buffer;\n      let offset = 0;\n      let count = 0;\n      let options = param4;\n\n      if (param1 instanceof Buffer) {\n        buffer = param1;\n        offset = param2 || 0;\n        count = typeof param3 === \"number\" ? param3 : 0;\n      } else {\n        offset = typeof param1 === \"number\" ? param1 : 0;\n        count = typeof param2 === \"number\" ? param2 : 0;\n        options = param3 || {};\n      }\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-downloadToBuffer\", options);\n\n      try {\n        if (!options.blockSize) {\n          options.blockSize = 0;\n        }\n\n        if (options.blockSize < 0) {\n          throw new RangeError(\"blockSize option must be >= 0\");\n        }\n\n        if (options.blockSize === 0) {\n          options.blockSize = DEFAULT_BLOB_DOWNLOAD_BLOCK_BYTES;\n        }\n\n        if (offset < 0) {\n          throw new RangeError(\"offset option must be >= 0\");\n        }\n\n        if (count && count <= 0) {\n          throw new RangeError(\"count option must be greater than 0\");\n        }\n\n        if (!options.conditions) {\n          options.conditions = {};\n        } // Customer doesn't specify length, get it\n\n\n        if (!count) {\n          const response = yield _this16.getProperties(Object.assign(Object.assign({}, options), {\n            tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions))\n          }));\n          count = response.contentLength - offset;\n\n          if (count < 0) {\n            throw new RangeError(`offset ${offset} shouldn't be larger than blob size ${response.contentLength}`);\n          }\n        } // Allocate the buffer of size = count if the buffer is not provided\n\n\n        if (!buffer) {\n          try {\n            buffer = Buffer.alloc(count);\n          } catch (error) {\n            throw new Error(`Unable to allocate the buffer of size: ${count}(in bytes). Please try passing your own buffer to the \"downloadToBuffer\" method or try using other methods like \"download\" or \"downloadToFile\".\\t ${error.message}`);\n          }\n        }\n\n        if (buffer.length < count) {\n          throw new RangeError(`The buffer's size should be equal to or larger than the request count of bytes: ${count}`);\n        }\n\n        let transferProgress = 0;\n        const batch = new Batch(options.concurrency);\n\n        for (let off = offset; off < offset + count; off = off + options.blockSize) {\n          batch.addOperation( /*#__PURE__*/_asyncToGenerator(function* () {\n            // Exclusive chunk end position\n            let chunkEnd = offset + count;\n\n            if (off + options.blockSize < chunkEnd) {\n              chunkEnd = off + options.blockSize;\n            }\n\n            const response = yield _this16.download(off, chunkEnd - off, {\n              abortSignal: options.abortSignal,\n              conditions: options.conditions,\n              maxRetryRequests: options.maxRetryRequestsPerBlock,\n              customerProvidedKey: options.customerProvidedKey,\n              tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions))\n            });\n            const stream = response.readableStreamBody;\n            yield streamToBuffer(stream, buffer, off - offset, chunkEnd - offset); // Update progress after block is downloaded, in case of block trying\n            // Could provide finer grained progress updating inside HTTP requests,\n            // only if convenience layer download try is enabled\n\n            transferProgress += chunkEnd - off;\n\n            if (options.onProgress) {\n              options.onProgress({\n                loadedBytes: transferProgress\n              });\n            }\n          }));\n        }\n\n        yield batch.do();\n        return buffer;\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * ONLY AVAILABLE IN NODE.JS RUNTIME.\n   *\n   * Downloads an Azure Blob to a local file.\n   * Fails if the the given file path already exits.\n   * Offset and count are optional, pass 0 and undefined respectively to download the entire blob.\n   *\n   * @param filePath -\n   * @param offset - From which position of the block blob to download.\n   * @param count - How much data to be downloaded. Will download to the end when passing undefined.\n   * @param options - Options to Blob download options.\n   * @returns The response data for blob download operation,\n   *                                                 but with readableStreamBody set to undefined since its\n   *                                                 content is already read and written into a local file\n   *                                                 at the specified path.\n   */\n\n\n  downloadToFile(filePath, offset = 0, count, options = {}) {\n    var _this17 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-downloadToFile\", options);\n\n      try {\n        const response = yield _this17.download(offset, count, Object.assign(Object.assign({}, options), {\n          tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions))\n        }));\n\n        if (response.readableStreamBody) {\n          yield readStreamToLocalFile(response.readableStreamBody, filePath);\n        } // The stream is no longer accessible so setting it to undefined.\n\n\n        response.blobDownloadStream = undefined;\n        return response;\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n  getBlobAndContainerNamesFromUrl() {\n    let containerName;\n    let blobName;\n\n    try {\n      //  URL may look like the following\n      // \"https://myaccount.blob.core.windows.net/mycontainer/blob?sasString\";\n      // \"https://myaccount.blob.core.windows.net/mycontainer/blob\";\n      // \"https://myaccount.blob.core.windows.net/mycontainer/blob/a.txt?sasString\";\n      // \"https://myaccount.blob.core.windows.net/mycontainer/blob/a.txt\";\n      // IPv4/IPv6 address hosts, Endpoints - `http://127.0.0.1:10000/devstoreaccount1/containername/blob`\n      // http://localhost:10001/devstoreaccount1/containername/blob\n      const parsedUrl = URLBuilder.parse(this.url);\n\n      if (parsedUrl.getHost().split(\".\")[1] === \"blob\") {\n        // \"https://myaccount.blob.core.windows.net/containername/blob\".\n        // .getPath() -> /containername/blob\n        const pathComponents = parsedUrl.getPath().match(\"/([^/]*)(/(.*))?\");\n        containerName = pathComponents[1];\n        blobName = pathComponents[3];\n      } else if (isIpEndpointStyle(parsedUrl)) {\n        // IPv4/IPv6 address hosts... Example - http://192.0.0.10:10001/devstoreaccount1/containername/blob\n        // Single word domain without a [dot] in the endpoint... Example - http://localhost:10001/devstoreaccount1/containername/blob\n        // .getPath() -> /devstoreaccount1/containername/blob\n        const pathComponents = parsedUrl.getPath().match(\"/([^/]*)/([^/]*)(/(.*))?\");\n        containerName = pathComponents[2];\n        blobName = pathComponents[4];\n      } else {\n        // \"https://customdomain.com/containername/blob\".\n        // .getPath() -> /containername/blob\n        const pathComponents = parsedUrl.getPath().match(\"/([^/]*)(/(.*))?\");\n        containerName = pathComponents[1];\n        blobName = pathComponents[3];\n      } // decode the encoded blobName, containerName - to get all the special characters that might be present in them\n\n\n      containerName = decodeURIComponent(containerName);\n      blobName = decodeURIComponent(blobName); // Azure Storage Server will replace \"\\\" with \"/\" in the blob names\n      //   doing the same in the SDK side so that the user doesn't have to replace \"\\\" instances in the blobName\n\n      blobName = blobName.replace(/\\\\/g, \"/\");\n\n      if (!containerName) {\n        throw new Error(\"Provided containerName is invalid.\");\n      }\n\n      return {\n        blobName,\n        containerName\n      };\n    } catch (error) {\n      throw new Error(\"Unable to extract blobName and containerName with provided information.\");\n    }\n  }\n  /**\n   * Asynchronously copies a blob to a destination within the storage account.\n   * In version 2012-02-12 and later, the source for a Copy Blob operation can be\n   * a committed blob in any Azure storage account.\n   * Beginning with version 2015-02-21, the source for a Copy Blob operation can be\n   * an Azure file in any Azure storage account.\n   * Only storage accounts created on or after June 7th, 2012 allow the Copy Blob\n   * operation to copy from another storage account.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/copy-blob\n   *\n   * @param copySource - url to the source Azure Blob/File.\n   * @param options - Optional options to the Blob Start Copy From URL operation.\n   */\n\n\n  startCopyFromURL(copySource, options = {}) {\n    var _this18 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b, _c;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-startCopyFromURL\", options);\n      options.conditions = options.conditions || {};\n      options.sourceConditions = options.sourceConditions || {};\n\n      try {\n        return yield _this18.blobContext.startCopyFromURL(copySource, Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          metadata: options.metadata,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          sourceModifiedAccessConditions: {\n            sourceIfMatch: options.sourceConditions.ifMatch,\n            sourceIfModifiedSince: options.sourceConditions.ifModifiedSince,\n            sourceIfNoneMatch: options.sourceConditions.ifNoneMatch,\n            sourceIfUnmodifiedSince: options.sourceConditions.ifUnmodifiedSince,\n            sourceIfTags: options.sourceConditions.tagConditions\n          },\n          immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,\n          immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,\n          legalHold: options.legalHold,\n          rehydratePriority: options.rehydratePriority,\n          tier: toAccessTier(options.tier),\n          blobTagsString: toBlobTagsString(options.tags),\n          sealBlob: options.sealBlob\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Only available for BlobClient constructed with a shared key credential.\n   *\n   * Generates a Blob Service Shared Access Signature (SAS) URI based on the client properties\n   * and parameters passed in. The SAS is signed by the shared key credential of the client.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas\n   *\n   * @param options - Optional parameters.\n   * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.\n   */\n\n\n  generateSasUrl(options) {\n    return new Promise(resolve => {\n      if (!(this.credential instanceof StorageSharedKeyCredential)) {\n        throw new RangeError(\"Can only generate the SAS when the client is initialized with a shared key credential\");\n      }\n\n      const sas = generateBlobSASQueryParameters(Object.assign({\n        containerName: this._containerName,\n        blobName: this._name,\n        snapshotTime: this._snapshot,\n        versionId: this._versionId\n      }, options), this.credential).toString();\n      resolve(appendToURLQuery(this.url, sas));\n    });\n  }\n  /**\n   * Delete the immutablility policy on the blob.\n   *\n   * @param options - Optional options to delete immutability policy on the blob.\n   */\n\n\n  deleteImmutabilityPolicy(options) {\n    var _this19 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-deleteImmutabilityPolicy\", options);\n\n      try {\n        return yield _this19.blobContext.deleteImmutabilityPolicy(Object.assign({\n          abortSignal: options === null || options === void 0 ? void 0 : options.abortSignal\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Set immutablility policy on the blob.\n   *\n   * @param options - Optional options to set immutability policy on the blob.\n   */\n\n\n  setImmutabilityPolicy(immutabilityPolicy, options) {\n    var _this20 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-setImmutabilityPolicy\", options);\n\n      try {\n        return yield _this20.blobContext.setImmutabilityPolicy(Object.assign({\n          abortSignal: options === null || options === void 0 ? void 0 : options.abortSignal,\n          immutabilityPolicyExpiry: immutabilityPolicy.expiriesOn,\n          immutabilityPolicyMode: immutabilityPolicy.policyMode,\n          modifiedAccessConditions: options === null || options === void 0 ? void 0 : options.modifiedAccessCondition\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Set legal hold on the blob.\n   *\n   * @param options - Optional options to set legal hold on the blob.\n   */\n\n\n  setLegalHold(legalHoldEnabled, options) {\n    var _this21 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlobClient-setLegalHold\", options);\n\n      try {\n        return yield _this21.blobContext.setLegalHold(legalHoldEnabled, Object.assign({\n          abortSignal: options === null || options === void 0 ? void 0 : options.abortSignal\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n}\n/**\n * AppendBlobClient defines a set of operations applicable to append blobs.\n */\n\nexport class AppendBlobClient extends BlobClient {\n  constructor(urlOrConnectionString, credentialOrPipelineOrContainerName, blobNameOrOptions, // Legacy, no fix for eslint error without breaking. Disable it for this interface.\n\n  /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/\n  options) {\n    // In TypeScript we cannot simply pass all parameters to super() like below so have to duplicate the code instead.\n    //   super(s, credentialOrPipelineOrContainerNameOrOptions, blobNameOrOptions, options);\n    let pipeline;\n    let url;\n    options = options || {};\n\n    if (isPipelineLike(credentialOrPipelineOrContainerName)) {\n      // (url: string, pipeline: Pipeline)\n      url = urlOrConnectionString;\n      pipeline = credentialOrPipelineOrContainerName;\n    } else if (isNode && credentialOrPipelineOrContainerName instanceof StorageSharedKeyCredential || credentialOrPipelineOrContainerName instanceof AnonymousCredential || isTokenCredential(credentialOrPipelineOrContainerName)) {\n      // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)      url = urlOrConnectionString;\n      url = urlOrConnectionString;\n      options = blobNameOrOptions;\n      pipeline = newPipeline(credentialOrPipelineOrContainerName, options);\n    } else if (!credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName !== \"string\") {\n      // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)\n      url = urlOrConnectionString; // The second parameter is undefined. Use anonymous credential.\n\n      pipeline = newPipeline(new AnonymousCredential(), options);\n    } else if (credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName === \"string\" && blobNameOrOptions && typeof blobNameOrOptions === \"string\") {\n      // (connectionString: string, containerName: string, blobName: string, options?: StoragePipelineOptions)\n      const containerName = credentialOrPipelineOrContainerName;\n      const blobName = blobNameOrOptions;\n      const extractedCreds = extractConnectionStringParts(urlOrConnectionString);\n\n      if (extractedCreds.kind === \"AccountConnString\") {\n        if (isNode) {\n          const sharedKeyCredential = new StorageSharedKeyCredential(extractedCreds.accountName, extractedCreds.accountKey);\n          url = appendToURLPath(appendToURLPath(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName));\n\n          if (!options.proxyOptions) {\n            options.proxyOptions = getDefaultProxySettings(extractedCreds.proxyUri);\n          }\n\n          pipeline = newPipeline(sharedKeyCredential, options);\n        } else {\n          throw new Error(\"Account connection string is only supported in Node.js environment\");\n        }\n      } else if (extractedCreds.kind === \"SASConnString\") {\n        url = appendToURLPath(appendToURLPath(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName)) + \"?\" + extractedCreds.accountSas;\n        pipeline = newPipeline(new AnonymousCredential(), options);\n      } else {\n        throw new Error(\"Connection string must be either an Account connection string or a SAS connection string\");\n      }\n    } else {\n      throw new Error(\"Expecting non-empty strings for containerName and blobName parameters\");\n    }\n\n    super(url, pipeline);\n    this.appendBlobContext = new AppendBlob(this.storageClientContext);\n  }\n  /**\n   * Creates a new AppendBlobClient object identical to the source but with the\n   * specified snapshot timestamp.\n   * Provide \"\" will remove the snapshot and return a Client to the base blob.\n   *\n   * @param snapshot - The snapshot timestamp.\n   * @returns A new AppendBlobClient object identical to the source but with the specified snapshot timestamp.\n   */\n\n\n  withSnapshot(snapshot) {\n    return new AppendBlobClient(setURLParameter(this.url, URLConstants.Parameters.SNAPSHOT, snapshot.length === 0 ? undefined : snapshot), this.pipeline);\n  }\n  /**\n   * Creates a 0-length append blob. Call AppendBlock to append data to an append blob.\n   * @see https://docs.microsoft.com/rest/api/storageservices/put-blob\n   *\n   * @param options - Options to the Append Block Create operation.\n   *\n   *\n   * Example usage:\n   *\n   * ```js\n   * const appendBlobClient = containerClient.getAppendBlobClient(\"<blob name>\");\n   * await appendBlobClient.create();\n   * ```\n   */\n\n\n  create(options = {}) {\n    var _this22 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b, _c;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"AppendBlobClient-create\", options);\n      options.conditions = options.conditions || {};\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this22.isHttps);\n        return yield _this22.appendBlobContext.create(0, Object.assign({\n          abortSignal: options.abortSignal,\n          blobHttpHeaders: options.blobHTTPHeaders,\n          leaseAccessConditions: options.conditions,\n          metadata: options.metadata,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope,\n          immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,\n          immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,\n          legalHold: options.legalHold,\n          blobTagsString: toBlobTagsString(options.tags)\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Creates a 0-length append blob. Call AppendBlock to append data to an append blob.\n   * If the blob with the same name already exists, the content of the existing blob will remain unchanged.\n   * @see https://docs.microsoft.com/rest/api/storageservices/put-blob\n   *\n   * @param options -\n   */\n\n\n  createIfNotExists(options = {}) {\n    var _this23 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"AppendBlobClient-createIfNotExists\", options);\n      const conditions = {\n        ifNoneMatch: ETagAny\n      };\n\n      try {\n        const res = yield _this23.create(Object.assign(Object.assign({}, updatedOptions), {\n          conditions\n        }));\n        return Object.assign(Object.assign({\n          succeeded: true\n        }, res), {\n          _response: res._response\n        });\n      } catch (e) {\n        if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === \"BlobAlreadyExists\") {\n          span.setStatus({\n            code: SpanStatusCode.ERROR,\n            message: \"Expected exception when creating a blob only if it does not already exist.\"\n          });\n          return Object.assign(Object.assign({\n            succeeded: false\n          }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), {\n            _response: e.response\n          });\n        }\n\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Seals the append blob, making it read only.\n   *\n   * @param options -\n   */\n\n\n  seal(options = {}) {\n    var _this24 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"AppendBlobClient-seal\", options);\n      options.conditions = options.conditions || {};\n\n      try {\n        return yield _this24.appendBlobContext.seal(Object.assign({\n          abortSignal: options.abortSignal,\n          appendPositionAccessConditions: options.conditions,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Commits a new block of data to the end of the existing append blob.\n   * @see https://docs.microsoft.com/rest/api/storageservices/append-block\n   *\n   * @param body - Data to be appended.\n   * @param contentLength - Length of the body in bytes.\n   * @param options - Options to the Append Block operation.\n   *\n   *\n   * Example usage:\n   *\n   * ```js\n   * const content = \"Hello World!\";\n   *\n   * // Create a new append blob and append data to the blob.\n   * const newAppendBlobClient = containerClient.getAppendBlobClient(\"<blob name>\");\n   * await newAppendBlobClient.create();\n   * await newAppendBlobClient.appendBlock(content, content.length);\n   *\n   * // Append data to an existing append blob.\n   * const existingAppendBlobClient = containerClient.getAppendBlobClient(\"<blob name>\");\n   * await existingAppendBlobClient.appendBlock(content, content.length);\n   * ```\n   */\n\n\n  appendBlock(body, contentLength, options = {}) {\n    var _this25 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"AppendBlobClient-appendBlock\", options);\n      options.conditions = options.conditions || {};\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this25.isHttps);\n        return yield _this25.appendBlobContext.appendBlock(contentLength, body, Object.assign({\n          abortSignal: options.abortSignal,\n          appendPositionAccessConditions: options.conditions,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          requestOptions: {\n            onUploadProgress: options.onProgress\n          },\n          transactionalContentMD5: options.transactionalContentMD5,\n          transactionalContentCrc64: options.transactionalContentCrc64,\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * The Append Block operation commits a new block of data to the end of an existing append blob\n   * where the contents are read from a source url.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/append-block-from-url\n   *\n   * @param sourceURL -\n   *                 The url to the blob that will be the source of the copy. A source blob in the same storage account can\n   *                 be authenticated via Shared Key. However, if the source is a blob in another account, the source blob\n   *                 must either be public or must be authenticated via a shared access signature. If the source blob is\n   *                 public, no authentication is required to perform the operation.\n   * @param sourceOffset - Offset in source to be appended\n   * @param count - Number of bytes to be appended as a block\n   * @param options -\n   */\n\n\n  appendBlockFromURL(sourceURL, sourceOffset, count, options = {}) {\n    var _this26 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"AppendBlobClient-appendBlockFromURL\", options);\n      options.conditions = options.conditions || {};\n      options.sourceConditions = options.sourceConditions || {};\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this26.isHttps);\n        return yield _this26.appendBlobContext.appendBlockFromUrl(sourceURL, 0, Object.assign({\n          abortSignal: options.abortSignal,\n          sourceRange: rangeToString({\n            offset: sourceOffset,\n            count\n          }),\n          sourceContentMD5: options.sourceContentMD5,\n          sourceContentCrc64: options.sourceContentCrc64,\n          leaseAccessConditions: options.conditions,\n          appendPositionAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          sourceModifiedAccessConditions: {\n            sourceIfMatch: options.sourceConditions.ifMatch,\n            sourceIfModifiedSince: options.sourceConditions.ifModifiedSince,\n            sourceIfNoneMatch: options.sourceConditions.ifNoneMatch,\n            sourceIfUnmodifiedSince: options.sourceConditions.ifUnmodifiedSince\n          },\n          copySourceAuthorization: httpAuthorizationToString(options.sourceAuthorization),\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n}\n/**\n * BlockBlobClient defines a set of operations applicable to block blobs.\n */\n\nexport class BlockBlobClient extends BlobClient {\n  constructor(urlOrConnectionString, credentialOrPipelineOrContainerName, blobNameOrOptions, // Legacy, no fix for eslint error without breaking. Disable it for this interface.\n\n  /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/\n  options) {\n    // In TypeScript we cannot simply pass all parameters to super() like below so have to duplicate the code instead.\n    //   super(s, credentialOrPipelineOrContainerNameOrOptions, blobNameOrOptions, options);\n    let pipeline;\n    let url;\n    options = options || {};\n\n    if (isPipelineLike(credentialOrPipelineOrContainerName)) {\n      // (url: string, pipeline: Pipeline)\n      url = urlOrConnectionString;\n      pipeline = credentialOrPipelineOrContainerName;\n    } else if (isNode && credentialOrPipelineOrContainerName instanceof StorageSharedKeyCredential || credentialOrPipelineOrContainerName instanceof AnonymousCredential || isTokenCredential(credentialOrPipelineOrContainerName)) {\n      // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)\n      url = urlOrConnectionString;\n      options = blobNameOrOptions;\n      pipeline = newPipeline(credentialOrPipelineOrContainerName, options);\n    } else if (!credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName !== \"string\") {\n      // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)\n      // The second parameter is undefined. Use anonymous credential.\n      url = urlOrConnectionString;\n      pipeline = newPipeline(new AnonymousCredential(), options);\n    } else if (credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName === \"string\" && blobNameOrOptions && typeof blobNameOrOptions === \"string\") {\n      // (connectionString: string, containerName: string, blobName: string, options?: StoragePipelineOptions)\n      const containerName = credentialOrPipelineOrContainerName;\n      const blobName = blobNameOrOptions;\n      const extractedCreds = extractConnectionStringParts(urlOrConnectionString);\n\n      if (extractedCreds.kind === \"AccountConnString\") {\n        if (isNode) {\n          const sharedKeyCredential = new StorageSharedKeyCredential(extractedCreds.accountName, extractedCreds.accountKey);\n          url = appendToURLPath(appendToURLPath(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName));\n\n          if (!options.proxyOptions) {\n            options.proxyOptions = getDefaultProxySettings(extractedCreds.proxyUri);\n          }\n\n          pipeline = newPipeline(sharedKeyCredential, options);\n        } else {\n          throw new Error(\"Account connection string is only supported in Node.js environment\");\n        }\n      } else if (extractedCreds.kind === \"SASConnString\") {\n        url = appendToURLPath(appendToURLPath(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName)) + \"?\" + extractedCreds.accountSas;\n        pipeline = newPipeline(new AnonymousCredential(), options);\n      } else {\n        throw new Error(\"Connection string must be either an Account connection string or a SAS connection string\");\n      }\n    } else {\n      throw new Error(\"Expecting non-empty strings for containerName and blobName parameters\");\n    }\n\n    super(url, pipeline);\n    this.blockBlobContext = new BlockBlob(this.storageClientContext);\n    this._blobContext = new StorageBlob(this.storageClientContext);\n  }\n  /**\n   * Creates a new BlockBlobClient object identical to the source but with the\n   * specified snapshot timestamp.\n   * Provide \"\" will remove the snapshot and return a URL to the base blob.\n   *\n   * @param snapshot - The snapshot timestamp.\n   * @returns A new BlockBlobClient object identical to the source but with the specified snapshot timestamp.\n   */\n\n\n  withSnapshot(snapshot) {\n    return new BlockBlobClient(setURLParameter(this.url, URLConstants.Parameters.SNAPSHOT, snapshot.length === 0 ? undefined : snapshot), this.pipeline);\n  }\n  /**\n   * ONLY AVAILABLE IN NODE.JS RUNTIME.\n   *\n   * Quick query for a JSON or CSV formatted blob.\n   *\n   * Example usage (Node.js):\n   *\n   * ```js\n   * // Query and convert a blob to a string\n   * const queryBlockBlobResponse = await blockBlobClient.query(\"select * from BlobStorage\");\n   * const downloaded = (await streamToBuffer(queryBlockBlobResponse.readableStreamBody)).toString();\n   * console.log(\"Query blob content:\", downloaded);\n   *\n   * async function streamToBuffer(readableStream) {\n   *   return new Promise((resolve, reject) => {\n   *     const chunks = [];\n   *     readableStream.on(\"data\", (data) => {\n   *       chunks.push(data instanceof Buffer ? data : Buffer.from(data));\n   *     });\n   *     readableStream.on(\"end\", () => {\n   *       resolve(Buffer.concat(chunks));\n   *     });\n   *     readableStream.on(\"error\", reject);\n   *   });\n   * }\n   * ```\n   *\n   * @param query -\n   * @param options -\n   */\n\n\n  query(query, options = {}) {\n    var _this27 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      ensureCpkIfSpecified(options.customerProvidedKey, _this27.isHttps);\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-query\", options);\n\n      try {\n        if (!isNode) {\n          throw new Error(\"This operation currently is only supported in Node.js.\");\n        }\n\n        const response = yield _this27._blobContext.query(Object.assign({\n          abortSignal: options.abortSignal,\n          queryRequest: {\n            queryType: \"SQL\",\n            expression: query,\n            inputSerialization: toQuerySerialization(options.inputTextConfiguration),\n            outputSerialization: toQuerySerialization(options.outputTextConfiguration)\n          },\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n        return new BlobQueryResponse(response, {\n          abortSignal: options.abortSignal,\n          onProgress: options.onProgress,\n          onError: options.onError\n        });\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Creates a new block blob, or updates the content of an existing block blob.\n   * Updating an existing block blob overwrites any existing metadata on the blob.\n   * Partial updates are not supported; the content of the existing blob is\n   * overwritten with the new content. To perform a partial update of a block blob's,\n   * use {@link stageBlock} and {@link commitBlockList}.\n   *\n   * This is a non-parallel uploading method, please use {@link uploadFile},\n   * {@link uploadStream} or {@link uploadBrowserData} for better performance\n   * with concurrency uploading.\n   *\n   * @see https://docs.microsoft.com/rest/api/storageservices/put-blob\n   *\n   * @param body - Blob, string, ArrayBuffer, ArrayBufferView or a function\n   *                               which returns a new Readable stream whose offset is from data source beginning.\n   * @param contentLength - Length of body in bytes. Use Buffer.byteLength() to calculate body length for a\n   *                               string including non non-Base64/Hex-encoded characters.\n   * @param options - Options to the Block Blob Upload operation.\n   * @returns Response data for the Block Blob Upload operation.\n   *\n   * Example usage:\n   *\n   * ```js\n   * const content = \"Hello world!\";\n   * const uploadBlobResponse = await blockBlobClient.upload(content, content.length);\n   * ```\n   */\n\n\n  upload(body, contentLength, options = {}) {\n    var _this28 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b, _c;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-upload\", options);\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this28.isHttps);\n        return yield _this28.blockBlobContext.upload(contentLength, body, Object.assign({\n          abortSignal: options.abortSignal,\n          blobHttpHeaders: options.blobHTTPHeaders,\n          leaseAccessConditions: options.conditions,\n          metadata: options.metadata,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          requestOptions: {\n            onUploadProgress: options.onProgress\n          },\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope,\n          immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,\n          immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,\n          legalHold: options.legalHold,\n          tier: toAccessTier(options.tier),\n          blobTagsString: toBlobTagsString(options.tags)\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Creates a new Block Blob where the contents of the blob are read from a given URL.\n   * This API is supported beginning with the 2020-04-08 version. Partial updates\n   * are not supported with Put Blob from URL; the content of an existing blob is overwritten with\n   * the content of the new blob.  To perform partial updates to a block blobs contents using a\n   * source URL, use {@link stageBlockFromURL} and {@link commitBlockList}.\n   *\n   * @param sourceURL - Specifies the URL of the blob. The value\n   *                           may be a URL of up to 2 KB in length that specifies a blob.\n   *                           The value should be URL-encoded as it would appear\n   *                           in a request URI. The source blob must either be public\n   *                           or must be authenticated via a shared access signature.\n   *                           If the source blob is public, no authentication is required\n   *                           to perform the operation. Here are some examples of source object URLs:\n   *                           - https://myaccount.blob.core.windows.net/mycontainer/myblob\n   *                           - https://myaccount.blob.core.windows.net/mycontainer/myblob?snapshot=<DateTime>\n   * @param options - Optional parameters.\n   */\n\n\n  syncUploadFromURL(sourceURL, options = {}) {\n    var _this29 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b, _c, _d, _e;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-syncUploadFromURL\", options);\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this29.isHttps);\n        return yield _this29.blockBlobContext.putBlobFromUrl(0, sourceURL, Object.assign(Object.assign(Object.assign({}, options), {\n          blobHttpHeaders: options.blobHTTPHeaders,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: options.conditions.tagConditions\n          }),\n          sourceModifiedAccessConditions: {\n            sourceIfMatch: (_a = options.sourceConditions) === null || _a === void 0 ? void 0 : _a.ifMatch,\n            sourceIfModifiedSince: (_b = options.sourceConditions) === null || _b === void 0 ? void 0 : _b.ifModifiedSince,\n            sourceIfNoneMatch: (_c = options.sourceConditions) === null || _c === void 0 ? void 0 : _c.ifNoneMatch,\n            sourceIfUnmodifiedSince: (_d = options.sourceConditions) === null || _d === void 0 ? void 0 : _d.ifUnmodifiedSince,\n            sourceIfTags: (_e = options.sourceConditions) === null || _e === void 0 ? void 0 : _e.tagConditions\n          },\n          cpkInfo: options.customerProvidedKey,\n          copySourceAuthorization: httpAuthorizationToString(options.sourceAuthorization),\n          tier: toAccessTier(options.tier),\n          blobTagsString: toBlobTagsString(options.tags)\n        }), convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Uploads the specified block to the block blob's \"staging area\" to be later\n   * committed by a call to commitBlockList.\n   * @see https://docs.microsoft.com/rest/api/storageservices/put-block\n   *\n   * @param blockId - A 64-byte value that is base64-encoded\n   * @param body - Data to upload to the staging area.\n   * @param contentLength - Number of bytes to upload.\n   * @param options - Options to the Block Blob Stage Block operation.\n   * @returns Response data for the Block Blob Stage Block operation.\n   */\n\n\n  stageBlock(blockId, body, contentLength, options = {}) {\n    var _this30 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-stageBlock\", options);\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this30.isHttps);\n        return yield _this30.blockBlobContext.stageBlock(blockId, contentLength, body, Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          requestOptions: {\n            onUploadProgress: options.onProgress\n          },\n          transactionalContentMD5: options.transactionalContentMD5,\n          transactionalContentCrc64: options.transactionalContentCrc64,\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * The Stage Block From URL operation creates a new block to be committed as part\n   * of a blob where the contents are read from a URL.\n   * This API is available starting in version 2018-03-28.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/put-block-from-url\n   *\n   * @param blockId - A 64-byte value that is base64-encoded\n   * @param sourceURL - Specifies the URL of the blob. The value\n   *                           may be a URL of up to 2 KB in length that specifies a blob.\n   *                           The value should be URL-encoded as it would appear\n   *                           in a request URI. The source blob must either be public\n   *                           or must be authenticated via a shared access signature.\n   *                           If the source blob is public, no authentication is required\n   *                           to perform the operation. Here are some examples of source object URLs:\n   *                           - https://myaccount.blob.core.windows.net/mycontainer/myblob\n   *                           - https://myaccount.blob.core.windows.net/mycontainer/myblob?snapshot=<DateTime>\n   * @param offset - From which position of the blob to download, greater than or equal to 0\n   * @param count - How much data to be downloaded, greater than 0. Will download to the end when undefined\n   * @param options - Options to the Block Blob Stage Block From URL operation.\n   * @returns Response data for the Block Blob Stage Block From URL operation.\n   */\n\n\n  stageBlockFromURL(blockId, sourceURL, offset = 0, count, options = {}) {\n    var _this31 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-stageBlockFromURL\", options);\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this31.isHttps);\n        return yield _this31.blockBlobContext.stageBlockFromURL(blockId, 0, sourceURL, Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          sourceContentMD5: options.sourceContentMD5,\n          sourceContentCrc64: options.sourceContentCrc64,\n          sourceRange: offset === 0 && !count ? undefined : rangeToString({\n            offset,\n            count\n          }),\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope,\n          copySourceAuthorization: httpAuthorizationToString(options.sourceAuthorization)\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Writes a blob by specifying the list of block IDs that make up the blob.\n   * In order to be written as part of a blob, a block must have been successfully written\n   * to the server in a prior {@link stageBlock} operation. You can call {@link commitBlockList} to\n   * update a blob by uploading only those blocks that have changed, then committing the new and existing\n   * blocks together. Any blocks not specified in the block list and permanently deleted.\n   * @see https://docs.microsoft.com/rest/api/storageservices/put-block-list\n   *\n   * @param blocks -  Array of 64-byte value that is base64-encoded\n   * @param options - Options to the Block Blob Commit Block List operation.\n   * @returns Response data for the Block Blob Commit Block List operation.\n   */\n\n\n  commitBlockList(blocks, options = {}) {\n    var _this32 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b, _c;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-commitBlockList\", options);\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this32.isHttps);\n        return yield _this32.blockBlobContext.commitBlockList({\n          latest: blocks\n        }, Object.assign({\n          abortSignal: options.abortSignal,\n          blobHttpHeaders: options.blobHTTPHeaders,\n          leaseAccessConditions: options.conditions,\n          metadata: options.metadata,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope,\n          immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,\n          immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,\n          legalHold: options.legalHold,\n          tier: toAccessTier(options.tier),\n          blobTagsString: toBlobTagsString(options.tags)\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Returns the list of blocks that have been uploaded as part of a block blob\n   * using the specified block list filter.\n   * @see https://docs.microsoft.com/rest/api/storageservices/get-block-list\n   *\n   * @param listType - Specifies whether to return the list of committed blocks,\n   *                                        the list of uncommitted blocks, or both lists together.\n   * @param options - Options to the Block Blob Get Block List operation.\n   * @returns Response data for the Block Blob Get Block List operation.\n   */\n\n\n  getBlockList(listType, options = {}) {\n    var _this33 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-getBlockList\", options);\n\n      try {\n        const res = yield _this33.blockBlobContext.getBlockList(listType, Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n\n        if (!res.committedBlocks) {\n          res.committedBlocks = [];\n        }\n\n        if (!res.uncommittedBlocks) {\n          res.uncommittedBlocks = [];\n        }\n\n        return res;\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  } // High level functions\n\n  /**\n   * Uploads a Buffer(Node.js)/Blob(browsers)/ArrayBuffer/ArrayBufferView object to a BlockBlob.\n   *\n   * When data length is no more than the specifiled {@link BlockBlobParallelUploadOptions.maxSingleShotSize} (default is\n   * {@link BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES}), this method will use 1 {@link upload} call to finish the upload.\n   * Otherwise, this method will call {@link stageBlock} to upload blocks, and finally call {@link commitBlockList}\n   * to commit the block list.\n   *\n   * A common {@link BlockBlobParallelUploadOptions.blobHTTPHeaders} option to set is\n   * `blobContentType`, enabling the browser to provide\n   * functionality based on file type.\n   *\n   * @param data - Buffer(Node.js), Blob, ArrayBuffer or ArrayBufferView\n   * @param options -\n   */\n\n\n  uploadData(data, options = {}) {\n    var _this34 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-uploadData\", options);\n\n      try {\n        if (isNode) {\n          let buffer;\n\n          if (data instanceof Buffer) {\n            buffer = data;\n          } else if (data instanceof ArrayBuffer) {\n            buffer = Buffer.from(data);\n          } else {\n            data = data;\n            buffer = Buffer.from(data.buffer, data.byteOffset, data.byteLength);\n          }\n\n          return _this34.uploadSeekableInternal((offset, size) => buffer.slice(offset, offset + size), buffer.byteLength, updatedOptions);\n        } else {\n          const browserBlob = new Blob([data]);\n          return _this34.uploadSeekableInternal((offset, size) => browserBlob.slice(offset, offset + size), browserBlob.size, updatedOptions);\n        }\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * ONLY AVAILABLE IN BROWSERS.\n   *\n   * Uploads a browser Blob/File/ArrayBuffer/ArrayBufferView object to block blob.\n   *\n   * When buffer length lesser than or equal to 256MB, this method will use 1 upload call to finish the upload.\n   * Otherwise, this method will call {@link stageBlock} to upload blocks, and finally call\n   * {@link commitBlockList} to commit the block list.\n   *\n   * A common {@link BlockBlobParallelUploadOptions.blobHTTPHeaders} option to set is\n   * `blobContentType`, enabling the browser to provide\n   * functionality based on file type.\n   *\n   * @deprecated Use {@link uploadData} instead.\n   *\n   * @param browserData - Blob, File, ArrayBuffer or ArrayBufferView\n   * @param options - Options to upload browser data.\n   * @returns Response data for the Blob Upload operation.\n   */\n\n\n  uploadBrowserData(browserData, options = {}) {\n    var _this35 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-uploadBrowserData\", options);\n\n      try {\n        const browserBlob = new Blob([browserData]);\n        return yield _this35.uploadSeekableInternal((offset, size) => browserBlob.slice(offset, offset + size), browserBlob.size, updatedOptions);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   *\n   * Uploads data to block blob. Requires a bodyFactory as the data source,\n   * which need to return a {@link HttpRequestBody} object with the offset and size provided.\n   *\n   * When data length is no more than the specified {@link BlockBlobParallelUploadOptions.maxSingleShotSize} (default is\n   * {@link BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES}), this method will use 1 {@link upload} call to finish the upload.\n   * Otherwise, this method will call {@link stageBlock} to upload blocks, and finally call {@link commitBlockList}\n   * to commit the block list.\n   *\n   * @param bodyFactory -\n   * @param size - size of the data to upload.\n   * @param options - Options to Upload to Block Blob operation.\n   * @returns Response data for the Blob Upload operation.\n   */\n\n\n  uploadSeekableInternal(bodyFactory, size, options = {}) {\n    var _this36 = this;\n\n    return _asyncToGenerator(function* () {\n      if (!options.blockSize) {\n        options.blockSize = 0;\n      }\n\n      if (options.blockSize < 0 || options.blockSize > BLOCK_BLOB_MAX_STAGE_BLOCK_BYTES) {\n        throw new RangeError(`blockSize option must be >= 0 and <= ${BLOCK_BLOB_MAX_STAGE_BLOCK_BYTES}`);\n      }\n\n      if (options.maxSingleShotSize !== 0 && !options.maxSingleShotSize) {\n        options.maxSingleShotSize = BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES;\n      }\n\n      if (options.maxSingleShotSize < 0 || options.maxSingleShotSize > BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES) {\n        throw new RangeError(`maxSingleShotSize option must be >= 0 and <= ${BLOCK_BLOB_MAX_UPLOAD_BLOB_BYTES}`);\n      }\n\n      if (options.blockSize === 0) {\n        if (size > BLOCK_BLOB_MAX_STAGE_BLOCK_BYTES * BLOCK_BLOB_MAX_BLOCKS) {\n          throw new RangeError(`${size} is too larger to upload to a block blob.`);\n        }\n\n        if (size > options.maxSingleShotSize) {\n          options.blockSize = Math.ceil(size / BLOCK_BLOB_MAX_BLOCKS);\n\n          if (options.blockSize < DEFAULT_BLOB_DOWNLOAD_BLOCK_BYTES) {\n            options.blockSize = DEFAULT_BLOB_DOWNLOAD_BLOCK_BYTES;\n          }\n        }\n      }\n\n      if (!options.blobHTTPHeaders) {\n        options.blobHTTPHeaders = {};\n      }\n\n      if (!options.conditions) {\n        options.conditions = {};\n      }\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-uploadSeekableInternal\", options);\n\n      try {\n        if (size <= options.maxSingleShotSize) {\n          return yield _this36.upload(bodyFactory(0, size), size, updatedOptions);\n        }\n\n        const numBlocks = Math.floor((size - 1) / options.blockSize) + 1;\n\n        if (numBlocks > BLOCK_BLOB_MAX_BLOCKS) {\n          throw new RangeError(`The buffer's size is too big or the BlockSize is too small;` + `the number of blocks must be <= ${BLOCK_BLOB_MAX_BLOCKS}`);\n        }\n\n        const blockList = [];\n        const blockIDPrefix = generateUuid();\n        let transferProgress = 0;\n        const batch = new Batch(options.concurrency);\n\n        for (let i = 0; i < numBlocks; i++) {\n          batch.addOperation( /*#__PURE__*/_asyncToGenerator(function* () {\n            const blockID = generateBlockID(blockIDPrefix, i);\n            const start = options.blockSize * i;\n            const end = i === numBlocks - 1 ? size : start + options.blockSize;\n            const contentLength = end - start;\n            blockList.push(blockID);\n            yield _this36.stageBlock(blockID, bodyFactory(start, contentLength), contentLength, {\n              abortSignal: options.abortSignal,\n              conditions: options.conditions,\n              encryptionScope: options.encryptionScope,\n              tracingOptions: updatedOptions.tracingOptions\n            }); // Update progress after block is successfully uploaded to server, in case of block trying\n            // TODO: Hook with convenience layer progress event in finer level\n\n            transferProgress += contentLength;\n\n            if (options.onProgress) {\n              options.onProgress({\n                loadedBytes: transferProgress\n              });\n            }\n          }));\n        }\n\n        yield batch.do();\n        return _this36.commitBlockList(blockList, updatedOptions);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * ONLY AVAILABLE IN NODE.JS RUNTIME.\n   *\n   * Uploads a local file in blocks to a block blob.\n   *\n   * When file size lesser than or equal to 256MB, this method will use 1 upload call to finish the upload.\n   * Otherwise, this method will call stageBlock to upload blocks, and finally call commitBlockList\n   * to commit the block list.\n   *\n   * @param filePath - Full path of local file\n   * @param options - Options to Upload to Block Blob operation.\n   * @returns Response data for the Blob Upload operation.\n   */\n\n\n  uploadFile(filePath, options = {}) {\n    var _this37 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-uploadFile\", options);\n\n      try {\n        const size = (yield fsStat(filePath)).size;\n        return yield _this37.uploadSeekableInternal((offset, count) => {\n          return () => fsCreateReadStream(filePath, {\n            autoClose: true,\n            end: count ? offset + count - 1 : Infinity,\n            start: offset\n          });\n        }, size, Object.assign(Object.assign({}, options), {\n          tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions))\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * ONLY AVAILABLE IN NODE.JS RUNTIME.\n   *\n   * Uploads a Node.js Readable stream into block blob.\n   *\n   * PERFORMANCE IMPROVEMENT TIPS:\n   * * Input stream highWaterMark is better to set a same value with bufferSize\n   *    parameter, which will avoid Buffer.concat() operations.\n   *\n   * @param stream - Node.js Readable stream\n   * @param bufferSize - Size of every buffer allocated, also the block size in the uploaded block blob. Default value is 8MB\n   * @param maxConcurrency -  Max concurrency indicates the max number of buffers that can be allocated,\n   *                                 positive correlation with max uploading concurrency. Default value is 5\n   * @param options - Options to Upload Stream to Block Blob operation.\n   * @returns Response data for the Blob Upload operation.\n   */\n\n\n  uploadStream(stream, bufferSize = DEFAULT_BLOCK_BUFFER_SIZE_BYTES, maxConcurrency = 5, options = {}) {\n    var _this38 = this;\n\n    return _asyncToGenerator(function* () {\n      if (!options.blobHTTPHeaders) {\n        options.blobHTTPHeaders = {};\n      }\n\n      if (!options.conditions) {\n        options.conditions = {};\n      }\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"BlockBlobClient-uploadStream\", options);\n\n      try {\n        let blockNum = 0;\n        const blockIDPrefix = generateUuid();\n        let transferProgress = 0;\n        const blockList = [];\n        const scheduler = new BufferScheduler(stream, bufferSize, maxConcurrency, /*#__PURE__*/function () {\n          var _ref4 = _asyncToGenerator(function* (body, length) {\n            const blockID = generateBlockID(blockIDPrefix, blockNum);\n            blockList.push(blockID);\n            blockNum++;\n            yield _this38.stageBlock(blockID, body, length, {\n              conditions: options.conditions,\n              encryptionScope: options.encryptionScope,\n              tracingOptions: updatedOptions.tracingOptions\n            }); // Update progress after block is successfully uploaded to server, in case of block trying\n\n            transferProgress += length;\n\n            if (options.onProgress) {\n              options.onProgress({\n                loadedBytes: transferProgress\n              });\n            }\n          });\n\n          return function (_x2, _x3) {\n            return _ref4.apply(this, arguments);\n          };\n        }(), // concurrency should set a smaller value than maxConcurrency, which is helpful to\n        // reduce the possibility when a outgoing handler waits for stream data, in\n        // this situation, outgoing handlers are blocked.\n        // Outgoing queue shouldn't be empty.\n        Math.ceil(maxConcurrency / 4 * 3));\n        yield scheduler.do();\n        return yield _this38.commitBlockList(blockList, Object.assign(Object.assign({}, options), {\n          tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions))\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n}\n/**\n * PageBlobClient defines a set of operations applicable to page blobs.\n */\n\nexport class PageBlobClient extends BlobClient {\n  constructor(urlOrConnectionString, credentialOrPipelineOrContainerName, blobNameOrOptions, // Legacy, no fix for eslint error without breaking. Disable it for this interface.\n\n  /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options*/\n  options) {\n    // In TypeScript we cannot simply pass all parameters to super() like below so have to duplicate the code instead.\n    //   super(s, credentialOrPipelineOrContainerNameOrOptions, blobNameOrOptions, options);\n    let pipeline;\n    let url;\n    options = options || {};\n\n    if (isPipelineLike(credentialOrPipelineOrContainerName)) {\n      // (url: string, pipeline: Pipeline)\n      url = urlOrConnectionString;\n      pipeline = credentialOrPipelineOrContainerName;\n    } else if (isNode && credentialOrPipelineOrContainerName instanceof StorageSharedKeyCredential || credentialOrPipelineOrContainerName instanceof AnonymousCredential || isTokenCredential(credentialOrPipelineOrContainerName)) {\n      // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)\n      url = urlOrConnectionString;\n      options = blobNameOrOptions;\n      pipeline = newPipeline(credentialOrPipelineOrContainerName, options);\n    } else if (!credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName !== \"string\") {\n      // (url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions)\n      // The second parameter is undefined. Use anonymous credential.\n      url = urlOrConnectionString;\n      pipeline = newPipeline(new AnonymousCredential(), options);\n    } else if (credentialOrPipelineOrContainerName && typeof credentialOrPipelineOrContainerName === \"string\" && blobNameOrOptions && typeof blobNameOrOptions === \"string\") {\n      // (connectionString: string, containerName: string, blobName: string, options?: StoragePipelineOptions)\n      const containerName = credentialOrPipelineOrContainerName;\n      const blobName = blobNameOrOptions;\n      const extractedCreds = extractConnectionStringParts(urlOrConnectionString);\n\n      if (extractedCreds.kind === \"AccountConnString\") {\n        if (isNode) {\n          const sharedKeyCredential = new StorageSharedKeyCredential(extractedCreds.accountName, extractedCreds.accountKey);\n          url = appendToURLPath(appendToURLPath(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName));\n\n          if (!options.proxyOptions) {\n            options.proxyOptions = getDefaultProxySettings(extractedCreds.proxyUri);\n          }\n\n          pipeline = newPipeline(sharedKeyCredential, options);\n        } else {\n          throw new Error(\"Account connection string is only supported in Node.js environment\");\n        }\n      } else if (extractedCreds.kind === \"SASConnString\") {\n        url = appendToURLPath(appendToURLPath(extractedCreds.url, encodeURIComponent(containerName)), encodeURIComponent(blobName)) + \"?\" + extractedCreds.accountSas;\n        pipeline = newPipeline(new AnonymousCredential(), options);\n      } else {\n        throw new Error(\"Connection string must be either an Account connection string or a SAS connection string\");\n      }\n    } else {\n      throw new Error(\"Expecting non-empty strings for containerName and blobName parameters\");\n    }\n\n    super(url, pipeline);\n    this.pageBlobContext = new PageBlob(this.storageClientContext);\n  }\n  /**\n   * Creates a new PageBlobClient object identical to the source but with the\n   * specified snapshot timestamp.\n   * Provide \"\" will remove the snapshot and return a Client to the base blob.\n   *\n   * @param snapshot - The snapshot timestamp.\n   * @returns A new PageBlobClient object identical to the source but with the specified snapshot timestamp.\n   */\n\n\n  withSnapshot(snapshot) {\n    return new PageBlobClient(setURLParameter(this.url, URLConstants.Parameters.SNAPSHOT, snapshot.length === 0 ? undefined : snapshot), this.pipeline);\n  }\n  /**\n   * Creates a page blob of the specified length. Call uploadPages to upload data\n   * data to a page blob.\n   * @see https://docs.microsoft.com/rest/api/storageservices/put-blob\n   *\n   * @param size - size of the page blob.\n   * @param options - Options to the Page Blob Create operation.\n   * @returns Response data for the Page Blob Create operation.\n   */\n\n\n  create(size, options = {}) {\n    var _this39 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b, _c;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-create\", options);\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this39.isHttps);\n        return yield _this39.pageBlobContext.create(0, size, Object.assign({\n          abortSignal: options.abortSignal,\n          blobHttpHeaders: options.blobHTTPHeaders,\n          blobSequenceNumber: options.blobSequenceNumber,\n          leaseAccessConditions: options.conditions,\n          metadata: options.metadata,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope,\n          immutabilityPolicyExpiry: (_b = options.immutabilityPolicy) === null || _b === void 0 ? void 0 : _b.expiriesOn,\n          immutabilityPolicyMode: (_c = options.immutabilityPolicy) === null || _c === void 0 ? void 0 : _c.policyMode,\n          legalHold: options.legalHold,\n          tier: toAccessTier(options.tier),\n          blobTagsString: toBlobTagsString(options.tags)\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Creates a page blob of the specified length. Call uploadPages to upload data\n   * data to a page blob. If the blob with the same name already exists, the content\n   * of the existing blob will remain unchanged.\n   * @see https://docs.microsoft.com/rest/api/storageservices/put-blob\n   *\n   * @param size - size of the page blob.\n   * @param options -\n   */\n\n\n  createIfNotExists(size, options = {}) {\n    var _this40 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-createIfNotExists\", options);\n\n      try {\n        const conditions = {\n          ifNoneMatch: ETagAny\n        };\n        const res = yield _this40.create(size, Object.assign(Object.assign({}, options), {\n          conditions,\n          tracingOptions: updatedOptions.tracingOptions\n        }));\n        return Object.assign(Object.assign({\n          succeeded: true\n        }, res), {\n          _response: res._response\n        });\n      } catch (e) {\n        if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === \"BlobAlreadyExists\") {\n          span.setStatus({\n            code: SpanStatusCode.ERROR,\n            message: \"Expected exception when creating a blob only if it does not already exist.\"\n          });\n          return Object.assign(Object.assign({\n            succeeded: false\n          }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), {\n            _response: e.response\n          });\n        }\n\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Writes 1 or more pages to the page blob. The start and end offsets must be a multiple of 512.\n   * @see https://docs.microsoft.com/rest/api/storageservices/put-page\n   *\n   * @param body - Data to upload\n   * @param offset - Offset of destination page blob\n   * @param count - Content length of the body, also number of bytes to be uploaded\n   * @param options - Options to the Page Blob Upload Pages operation.\n   * @returns Response data for the Page Blob Upload Pages operation.\n   */\n\n\n  uploadPages(body, offset, count, options = {}) {\n    var _this41 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-uploadPages\", options);\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this41.isHttps);\n        return yield _this41.pageBlobContext.uploadPages(count, body, Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          requestOptions: {\n            onUploadProgress: options.onProgress\n          },\n          range: rangeToString({\n            offset,\n            count\n          }),\n          sequenceNumberAccessConditions: options.conditions,\n          transactionalContentMD5: options.transactionalContentMD5,\n          transactionalContentCrc64: options.transactionalContentCrc64,\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * The Upload Pages operation writes a range of pages to a page blob where the\n   * contents are read from a URL.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/put-page-from-url\n   *\n   * @param sourceURL - Specify a URL to the copy source, Shared Access Signature(SAS) maybe needed for authentication\n   * @param sourceOffset - The source offset to copy from. Pass 0 to copy from the beginning of source page blob\n   * @param destOffset - Offset of destination page blob\n   * @param count - Number of bytes to be uploaded from source page blob\n   * @param options -\n   */\n\n\n  uploadPagesFromURL(sourceURL, sourceOffset, destOffset, count, options = {}) {\n    var _this42 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      options.conditions = options.conditions || {};\n      options.sourceConditions = options.sourceConditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-uploadPagesFromURL\", options);\n\n      try {\n        ensureCpkIfSpecified(options.customerProvidedKey, _this42.isHttps);\n        return yield _this42.pageBlobContext.uploadPagesFromURL(sourceURL, rangeToString({\n          offset: sourceOffset,\n          count\n        }), 0, rangeToString({\n          offset: destOffset,\n          count\n        }), Object.assign({\n          abortSignal: options.abortSignal,\n          sourceContentMD5: options.sourceContentMD5,\n          sourceContentCrc64: options.sourceContentCrc64,\n          leaseAccessConditions: options.conditions,\n          sequenceNumberAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          sourceModifiedAccessConditions: {\n            sourceIfMatch: options.sourceConditions.ifMatch,\n            sourceIfModifiedSince: options.sourceConditions.ifModifiedSince,\n            sourceIfNoneMatch: options.sourceConditions.ifNoneMatch,\n            sourceIfUnmodifiedSince: options.sourceConditions.ifUnmodifiedSince\n          },\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope,\n          copySourceAuthorization: httpAuthorizationToString(options.sourceAuthorization)\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Frees the specified pages from the page blob.\n   * @see https://docs.microsoft.com/rest/api/storageservices/put-page\n   *\n   * @param offset - Starting byte position of the pages to clear.\n   * @param count - Number of bytes to clear.\n   * @param options - Options to the Page Blob Clear Pages operation.\n   * @returns Response data for the Page Blob Clear Pages operation.\n   */\n\n\n  clearPages(offset = 0, count, options = {}) {\n    var _this43 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-clearPages\", options);\n\n      try {\n        return yield _this43.pageBlobContext.clearPages(0, Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          range: rangeToString({\n            offset,\n            count\n          }),\n          sequenceNumberAccessConditions: options.conditions,\n          cpkInfo: options.customerProvidedKey,\n          encryptionScope: options.encryptionScope\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Returns the list of valid page ranges for a page blob or snapshot of a page blob.\n   * @see https://docs.microsoft.com/rest/api/storageservices/get-page-ranges\n   *\n   * @param offset - Starting byte position of the page ranges.\n   * @param count - Number of bytes to get.\n   * @param options - Options to the Page Blob Get Ranges operation.\n   * @returns Response data for the Page Blob Get Ranges operation.\n   */\n\n\n  getPageRanges(offset = 0, count, options = {}) {\n    var _this44 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-getPageRanges\", options);\n\n      try {\n        return yield _this44.pageBlobContext.getPageRanges(Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          range: rangeToString({\n            offset,\n            count\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions))).then(rangeResponseFromModel);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Gets the collection of page ranges that differ between a specified snapshot and this page blob.\n   * @see https://docs.microsoft.com/rest/api/storageservices/get-page-ranges\n   *\n   * @param offset - Starting byte position of the page blob\n   * @param count - Number of bytes to get ranges diff.\n   * @param prevSnapshot - Timestamp of snapshot to retrieve the difference.\n   * @param options - Options to the Page Blob Get Page Ranges Diff operation.\n   * @returns Response data for the Page Blob Get Page Range Diff operation.\n   */\n\n\n  getPageRangesDiff(offset, count, prevSnapshot, options = {}) {\n    var _this45 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-getPageRangesDiff\", options);\n\n      try {\n        return yield _this45.pageBlobContext.getPageRangesDiff(Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          prevsnapshot: prevSnapshot,\n          range: rangeToString({\n            offset,\n            count\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions))).then(rangeResponseFromModel);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Gets the collection of page ranges that differ between a specified snapshot and this page blob for managed disks.\n   * @see https://docs.microsoft.com/rest/api/storageservices/get-page-ranges\n   *\n   * @param offset - Starting byte position of the page blob\n   * @param count - Number of bytes to get ranges diff.\n   * @param prevSnapshotUrl - URL of snapshot to retrieve the difference.\n   * @param options - Options to the Page Blob Get Page Ranges Diff operation.\n   * @returns Response data for the Page Blob Get Page Range Diff operation.\n   */\n\n\n  getPageRangesDiffForManagedDisks(offset, count, prevSnapshotUrl, options = {}) {\n    var _this46 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-GetPageRangesDiffForManagedDisks\", options);\n\n      try {\n        return yield _this46.pageBlobContext.getPageRangesDiff(Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          prevSnapshotUrl,\n          range: rangeToString({\n            offset,\n            count\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions))).then(rangeResponseFromModel);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Resizes the page blob to the specified size (which must be a multiple of 512).\n   * @see https://docs.microsoft.com/rest/api/storageservices/set-blob-properties\n   *\n   * @param size - Target size\n   * @param options - Options to the Page Blob Resize operation.\n   * @returns Response data for the Page Blob Resize operation.\n   */\n\n\n  resize(size, options = {}) {\n    var _this47 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-resize\", options);\n\n      try {\n        return yield _this47.pageBlobContext.resize(size, Object.assign({\n          abortSignal: options.abortSignal,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          }),\n          encryptionScope: options.encryptionScope\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Sets a page blob's sequence number.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-properties\n   *\n   * @param sequenceNumberAction - Indicates how the service should modify the blob's sequence number.\n   * @param sequenceNumber - Required if sequenceNumberAction is max or update\n   * @param options - Options to the Page Blob Update Sequence Number operation.\n   * @returns Response data for the Page Blob Update Sequence Number operation.\n   */\n\n\n  updateSequenceNumber(sequenceNumberAction, sequenceNumber, options = {}) {\n    var _this48 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-updateSequenceNumber\", options);\n\n      try {\n        return yield _this48.pageBlobContext.updateSequenceNumber(sequenceNumberAction, Object.assign({\n          abortSignal: options.abortSignal,\n          blobSequenceNumber: sequenceNumber,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Begins an operation to start an incremental copy from one page blob's snapshot to this page blob.\n   * The snapshot is copied such that only the differential changes between the previously\n   * copied snapshot are transferred to the destination.\n   * The copied snapshots are complete copies of the original snapshot and can be read or copied from as usual.\n   * @see https://docs.microsoft.com/rest/api/storageservices/incremental-copy-blob\n   * @see https://docs.microsoft.com/en-us/azure/virtual-machines/windows/incremental-snapshots\n   *\n   * @param copySource - Specifies the name of the source page blob snapshot. For example,\n   *                            https://myaccount.blob.core.windows.net/mycontainer/myblob?snapshot=<DateTime>\n   * @param options - Options to the Page Blob Copy Incremental operation.\n   * @returns Response data for the Page Blob Copy Incremental operation.\n   */\n\n\n  startCopyIncremental(copySource, options = {}) {\n    var _this49 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"PageBlobClient-startCopyIncremental\", options);\n\n      try {\n        return yield _this49.pageBlobContext.copyIncremental(copySource, Object.assign({\n          abortSignal: options.abortSignal,\n          modifiedAccessConditions: Object.assign(Object.assign({}, options.conditions), {\n            ifTags: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.tagConditions\n          })\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n} //# sourceMappingURL=Clients.js.map","map":null,"metadata":{},"sourceType":"module"}